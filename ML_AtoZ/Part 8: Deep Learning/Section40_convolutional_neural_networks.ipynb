{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning A-Z™\n",
    "\n",
    "© Kirill Eremenko, Hadelin de Ponteves, SuperDataScience Team |\n",
    "[Super Data Science](http://www.superdatascience.com)\n",
    "\n",
    "Part 8: Deep Learning | Section 40: Convolutional Neural Networks (CNN)\n",
    "\n",
    "Created on Tue Apr  20, 2019\n",
    "@author: yinka_ola\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ---\n",
    "\n",
    "## Deep Learning:\n",
    "## Deep Learning is the most exciting and powerful branch of Machine Learning. \n",
    "## Deep Learning models can be used for a variety of complex tasks:\n",
    "\n",
    "## Artificial Neural Networks for Regression and Classification\n",
    "## Convolutional Neural Networks for Computer Vision\n",
    "## Recurrent Neural Networks for Time Series Analysis\n",
    "## Self Organizing Maps for Feature Extraction\n",
    "## Deep Boltzmann Machines for Recommendation Systems\n",
    "## Auto Encoders for Recommendation Systems\n",
    "\n",
    "## So what is deep learning?\n",
    "## Geoffery Hinton: Godfather of Deep learning: currently at Google\n",
    "## goal: mimic how the human brain operate and recreate it\n",
    "## human brain: one of the most powerful machine of learning\n",
    "## approx. 100 billion neuron in the human brain\n",
    "## create an artificial structure = artificail neural net\n",
    "## input layer + hidden layer + output layer\n",
    "## multiple hidden layer and connect each together \n",
    "\n",
    "## ---\n",
    "\n",
    "## In this part, you will understand and learn how to implement \n",
    "## Convolutional Neural Networks (CNN) for a Computer Vision task: Steps\n",
    "## What are CNN?\n",
    "## 1. Convolution\n",
    "## 1a. ReLU Layer\n",
    "## 2. (max) Pooling\n",
    "## 3. Flattening\n",
    "## 4. Full Connection\n",
    "## sunmmary\n",
    "\n",
    "## ---\n",
    "\n",
    "## What are CNN?:\n",
    "## Yann Lecun: godfather of CNN (now at Facebook)\n",
    "## optical illusion images\n",
    "## the brain processes certain features in an image and classifies it\n",
    "\n",
    "## Deep Learning History:\n",
    "## input image => CNN => Output label\n",
    "## Black and white image: 2d array\n",
    "## colour image: 3d array\n",
    "\n",
    "## 1. Convolution:\n",
    "## it combine integration of 2 fcn and it shows how one fcn modifies the shape of another \n",
    "## input image, feature detector/kernal/filter\n",
    "## the step of moving is called stride\n",
    "## feature map = activation map\n",
    "## are we losing information when applying a feature map? => A little\n",
    "## feature is how we see and detect things, we don't look at everythng\n",
    "## we create multiple feature maps to obtain  our first convolution layer\n",
    "## you can use feature detector to adjust/appy filters to your images\n",
    "## CNN is an ANN using convolution trick in the convolution layer\n",
    "## to preserve spatial structure in images for classification\n",
    "## to classify images/photographs or photos\n",
    "\n",
    "## 1a. ReLU Layer:\n",
    "## Rectified Linear Unit Layer\n",
    "## here we apply the rectifier function, to increase nonlinearity in our network\n",
    "## images themselves are nonlinear with non linear elements\n",
    "\n",
    "## 2. Max Pooling:\n",
    "## we want the CNN to recognize the object in different angels/light, etc. \n",
    "## CNN must have spatial invariants: it doesn't matter the the angle or variation\n",
    "## here you are recording the maximum numbers = pooled feature map\n",
    "## b/c we are taking the maximum, we are taking account of any distortion\n",
    "## we are reducing the parameter and preventing overfitting\n",
    "## pooling = down sampling\n",
    "## overall idea: the feature is still preserved\n",
    "## www.scs.ryerson.ca/~aharley/vis/conv/flat.html\n",
    "\n",
    "## 3. Flattening:\n",
    "## take a pooled feature map and flatteninto 1 long column\n",
    "## input image => Convolution layer => Pooling layer => flatten => add ANN layer\n",
    "\n",
    "## 4. Full Connection:\n",
    "## here the hidden layer is fully connected = fully connected layer\n",
    "## final neurons learn to listen to the neurons in the final fully conected layer\n",
    "## neurons votes, final neurons uses weigths to choose vote and predict class\n",
    "\n",
    "## Summary:\n",
    "## image => CNN layer => Pooling layer => flatten => fully connected layer => output\n",
    "\n",
    "\n",
    "## Softmax & Cross Entropy (addition)\n",
    "## softmax function makes neuron value to add up to 1\n",
    "\n",
    "\n",
    "## ---\n",
    "\n",
    "#Data Scenario: \n",
    "## a collection of images\n",
    "## classify if image is a cat or a dog\n",
    "## training set: 4k images each of dogs and cats\n",
    "## test set: 1k images each of dogs and cats\n",
    "## can use CNN deep learning for medical imaging \n",
    "\n",
    "\n",
    "## Python Libraries and Packages\n",
    "## Keras package integrates TensorFlow\n",
    "## in mac/pc terminal: conda install -c conda-forge keras\n",
    "## Theano: fast numerical computation library\n",
    "## GPU: processor for graphic puposes: much more powerful than CPU\n",
    "## Tensor: numerical computation\n",
    "## Theano + Tensor flow: for research purposes ( a lot of lines of code)\n",
    "## Keras: based on Theano + Tensor flow (few lines of code)\n",
    "## use keras to build deep learning algorithm efficiently\n",
    "\n",
    "## ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd #data\n",
    "import numpy as np #mathematics\n",
    "import os\n",
    "#plotting packages\n",
    "import matplotlib.pyplot as plt #plotting charts\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Part 1 - Data/image Preprocessing\n",
    "## this was done manually by classifying the images into folders\n",
    "\n",
    "# Part 1a - Building the CNN\n",
    "# Importing the Keras libraries and packages\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu')) #number of nodes\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-afb6ccc8070b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#note this code will take about 30 mins to run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m classifier.fit_generator(training_set, \n\u001b[0m\u001b[1;32m     25\u001b[0m                          \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                          \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Part 2 - Fitting the CNN to the images\n",
    "## search online for Keras documentation for line of codes to use\n",
    "## apply image augmentation on training set\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\n",
    "#note this code will take about 30 mins to run\n",
    "classifier.fit_generator(training_set, \n",
    "                         steps_per_epoch = 8000,\n",
    "                         epochs = 25,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Observation\n",
    "## we are interesting in the accuracy of the model\n",
    "## 75% accuracy on the test set  test set accuracy\n",
    "## goal: make the accuracy to reach that of the training of >` 80%\n",
    "\n",
    "## to improve accuracy, add a second convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(output_dim = 128, activation = 'relu')) #number of nodes\n",
    "classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "# Part 2 - Fitting the CNN to the images\n",
    "## search online for Keras documentation for line of codes to use\n",
    "## apply image augmentation on training set\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\n",
    "#note this code will take about 30 mins to run\n",
    "classifier.fit_generator(training_set, \n",
    "                         samples_per_epoch = 8000,\n",
    "                         epochs = 25,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ---\n",
    "## Observation\n",
    "## we are interesting in the accuracy of the model\n",
    "## 75% accuracy on the test set  test set accuracy\n",
    "## goal: make the accuracy to reach that of the training of >` 80%\n",
    "## indeed, we are at 86.7 %"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
